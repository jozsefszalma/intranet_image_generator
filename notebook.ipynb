{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License:\n",
    "Copyright 2023, Jozsef Szalma <br>\n",
    "Creative Commons Attribution-NonCommercial 4.0 International Public License<br>\n",
    "https://creativecommons.org/licenses/by-nc/4.0/legalcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up: \n",
    "1. Environment variables on the backend (e.g. in a .env file) \n",
    "- HF_KEY: Your Hugging Face API key \n",
    "- IMG_DIR_WIN and IMG_DIR_DOCKER: Location to store the generated images\n",
    "- PROMPT_PREFIX and PROMPT_SUFFIX: Optional, if you want to prefix or suffix the prompt with anything (e.g. cartoonish, kid-friendly)\n",
    "- NEGATIVE_PROMPT: Optional, but should be used for parental controls (e.g. add \"scary\" to prevent convergence on scary images, the same with NSFW concepts, etc.)\n",
    "- MODEL_ID: Optional, Hugging Face model ID, using SD 2.1 if not defined\n",
    "\n",
    "2. set a fixed LAN IP address on the machine running the backend and expose port 5000 to your **intra**net\n",
    "\n",
    "3. set up the IP address of the backend on the mobile app under the kebab menu (look for ⋮ in the upper right corner)\n",
    "\n",
    "4. As of now, to get the mobile app running, you need to set up a React Native development environment, compile the app from source and load the .apk onto an Android device using developer mode.<br>\n",
    "Here is a handy guide: https://reactnative.dev/docs/environment-setup?guide=native\n",
    "\n",
    "\n",
    "### Known issues and Disclaimers:\n",
    "- This is a hobby prototype that takes quite a bit of tech skills to get to work and is not production ready. You shouldn't use it if you don't understand the technology involved. Read the license terms, especially Section 5 – Disclaimer of Warranties and Limitation of Liability.\n",
    "- I couldn't test if Docker works at all, as my NVIDIA drivers do not want to play with Docker in my Windows Linux Subsystem\n",
    "- The mobile app still has the default Android icon and is named \"mobile_client\"\n",
    "- Minimal security (not making any attempts to sanitize inputs or authenticate clients), the backend is only intended to be used behind a NAT router for demo purposes, not ready to be exposed to the Internet. \n",
    "- I recommend setting up an extensive negative prompt as parental controls, in addition to using the Stability safety filter, and not letting kids play with diffusion models without adult supervision, as **most of these models will produce age-inappropriate content** with minimal effort and curiosity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from flask import Flask, request, send_from_directory\n",
    "from flask_restful import Api, Resource\n",
    "\n",
    "from huggingface_hub import login\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers.pipelines.stable_diffusion import StableDiffusionSafetyChecker\n",
    "from transformers import CLIPFeatureExtractor\n",
    "\n",
    "import torch\n",
    "\n",
    "import openai\n",
    "import json\n",
    "\n",
    "#huggingface key\n",
    "hf_key = os.getenv(\"HF_KEY\")\n",
    "\n",
    "#output directory\n",
    "image_dir = os.getenv(\"IMG_DIR_WIN\") \n",
    "\n",
    "#optional, if you want to prefix or suffix the prompt with anything (e.g. cartoonish, kids friendly)\n",
    "prompt_prefix = os.getenv(\"PROMPT_PREFIX\", \"\")\n",
    "prompt_suffix = os.getenv(\"PROMPT_SUFFIX\", \"\")\n",
    "\n",
    "#optional, can be used for parental controls (e.g. add \"scary\" to prevent convergence on scary images, et cetera)\n",
    "negative_prompt = os.getenv(\"NEGATIVE_PROMPT\",\"\")\n",
    "\n",
    "login(token=hf_key,add_to_git_credential=True)\n",
    "\n",
    "#Hugging Face model ID, using SD 2.1 if not defined in env\n",
    "model_id = os.getenv(\"MODEL_ID\",\"stabilityai/stable-diffusion-2-1\") \n",
    "\n",
    "\n",
    "#parental control model's parameters (GPT3)\n",
    "openai.api_key = os.getenv(\"OPENAI_KEY\")\n",
    "default_inhibitor = os.getenv(\"PROMPT_INHIBITOR\")\n",
    "inhibitor_model = \"text-davinci-003\"\n",
    "inhibitor_temp = 0.0\n",
    "inhibitor_token_limit = 200\n",
    "\n",
    "blank_prompt = \"clouds in the sky\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API calls to OpenAI\n",
    "\n",
    "import re\n",
    "\n",
    "def get_gpt (prompt):\n",
    "    \n",
    "    inhibitor_response = openai.Completion.create(\n",
    "            model = inhibitor_model,\n",
    "            prompt = default_inhibitor + \" \" + prompt,\n",
    "            temperature = inhibitor_temp,\n",
    "            max_tokens = inhibitor_token_limit,\n",
    "            n = 1\n",
    "        )\n",
    "    \n",
    "    \n",
    "    inhibitor_message = inhibitor_response.choices[0].text \n",
    "    json_text = re.search(r\"\\{.*\\}\", inhibitor_message).group(0)\n",
    "    print ('user input: ', prompt)\n",
    "    print ('inhibitor''s response',inhibitor_message)\n",
    "    try:\n",
    "        #inhibitor_decision = json.loads(inhibitor_message)['decision']\n",
    "        #inhibitor_explanation = json.loads(inhibitor_message)['explanation']\n",
    "        inhibitor_prompt = json.loads(json_text)['revised_prompt']\n",
    "\n",
    "    except:\n",
    "        print('inhibitor returned malformed response: ', inhibitor_message)\n",
    "        return prompt    \n",
    "    \n",
    "    return inhibitor_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_id == \"stabilityai/stable-diffusion-2-1\":\n",
    "    #SD 2.1 does not have the safety checker by default\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id, use_auth_token=True, \n",
    "                                                        safety_checker=StableDiffusionSafetyChecker.from_pretrained(\"CompVis/stable-diffusion-safety-checker\",torch_dtype=torch.float16),\n",
    "                                                        feature_extractor=CLIPFeatureExtractor.from_pretrained(\"openai/clip-vit-base-patch32\",torch_dtype=torch.float16),\n",
    "                                                        torch_dtype=torch.float16)\n",
    "\n",
    "\n",
    "else:\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(model_id, use_auth_token=True, \n",
    "                                                    torch_dtype=torch.float16)\n",
    "\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "api = Api(app)\n",
    "\n",
    "#image generator api, generates the image and returns a GUID that acts as key for image retrieval \n",
    "class ImageGeneration(Resource):\n",
    "    def post(self):\n",
    "        data = request.get_json()\n",
    "        prompt = data['prompt']\n",
    "        if prompt == \"\" : prompt = blank_prompt\n",
    "        prompt = get_gpt(prompt)\n",
    "        image_id = str(uuid.uuid4())\n",
    "\n",
    "        result = pipe(prompt = prompt_prefix + \" \" + prompt + \" \" + prompt_suffix,\n",
    "                      negative_prompt = negative_prompt)\n",
    "\n",
    "        nsfw_loop_count = 0\n",
    "        while result.nsfw_content_detected[0]:\n",
    "            result = pipe(prompt = prompt_prefix + \" \" + prompt + \" \" + prompt_suffix,\n",
    "                      negative_prompt = negative_prompt)\n",
    "            nsfw_loop_count += 1\n",
    "            if nsfw_loop_count > 10 : \n",
    "                result = pipe(prompt = \"\",\n",
    "                      negative_prompt = negative_prompt)\n",
    "                break\n",
    "            \n",
    "            \n",
    "        image = result.images[0]\n",
    "        image.save(os.path.join(image_dir, f\"{image_id}.png\"))\n",
    "        \n",
    "        print(\"nsfw? \", result.nsfw_content_detected[0])\n",
    "        print(\"prompt: \", prompt)\n",
    "        print(\"image id: \", image_id)\n",
    "       \n",
    "        return {'guid': image_id}\n",
    "\n",
    "#image retrieval api, serves the image that matches the GUID provided\n",
    "class ImageRetrieval(Resource):\n",
    "    def get(self):\n",
    "        image_id = request.args.get('guid')\n",
    "        print(image_id)\n",
    "        return send_from_directory(image_dir, f\"{image_id}.png\")\n",
    "\n",
    "api.add_resource(ImageGeneration, '/generate/')\n",
    "api.add_resource(ImageRetrieval, '/image/')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run(debug=True, use_reloader=False, host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-sd-server",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
